import os
import subprocess
import pandas as pd
from concurrent.futures import ProcessPoolExecutor, as_completed
import shutil

import config as cfg


def _compress_single(args):
    """ë‹¨ì¼ íŒŒì¼ VVC ì••ì¶• (ë©€í‹°í”„ë¡œì„¸ì‹± ì›Œì»¤ìš©)"""
    row_dict, input_root, output_root, qp = args
    file_name = row_dict["file_name"]
    base_name = row_dict["base_name"]
    width = int(row_dict["width"])
    height = int(row_dict["height"])
    fps = int(row_dict["fps"])
    frame_count = int(row_dict["frame_count"])
    priority = row_dict.get("compress_priority", 999)

    input_path = os.path.join(input_root, file_name)
    output_dir = os.path.join(output_root, f"qp{qp}")
    out_bin = os.path.join(output_dir, f"{base_name}_qp{qp}.bin")
    out_yuv = os.path.join(output_dir, f"{base_name}_qp{qp}.yuv")

    if not os.path.exists(input_path):
        return priority, base_name, qp, False, f"ì…ë ¥ íŒŒì¼ ì—†ìŒ: {input_path}"

    # VVC ì¸ì½”ë”© ëª…ë ¹ì–´ êµ¬ì„±
    cmd = [
        cfg.VVC_ENCODER_APP_PATH,
        "-i",
        input_path,
        "-c",
        cfg.VVC_CFG_PATH,
        "-q",
        str(qp),
        "-wdt",
        str(width),
        "-hgt",
        str(height),
        "-fr",
        str(fps),
        "-f",
        str(frame_count),
        "--InputBitDepth=8",
        "--InternalBitDepth=8",
        "--OutputBitDepth=8",
        "-b",
        out_bin,
        "-o",
        out_yuv,
    ]

    try:
        # VVCëŠ” ë¡œê·¸ê°€ ë§ìœ¼ë¯€ë¡œ capture_output=Trueë¡œ ìˆ¨ê¹€ (ì—ëŸ¬ ì‹œ í™•ì¸)
        subprocess.run(cmd, check=True, capture_output=True, text=True)
        return priority, base_name, qp, True, None
    except subprocess.CalledProcessError as e:
        err_msg = str(e.stderr) if e.stderr else str(e)
        return priority, base_name, qp, False, err_msg


def compress_vcm_vvc(input_root, output_root, qp, job_df, max_workers=None):
    """metadata_vcm + vcm_analysis_report ê¸°ë°˜ VVC ì••ì¶• (ProcessPoolExecutor ë³‘ë ¬í™”)"""
    if max_workers is None:
        max_workers = 4  # VVCëŠ” ë¬´ê±°ìš°ë¯€ë¡œ ê¸°ë³¸ê°’ ë³´ìˆ˜ì ìœ¼ë¡œ ì„¤ì •

    rows = job_df.to_dict("records")
    tasks = [(r, input_root, output_root, qp) for r in rows]

    with ProcessPoolExecutor(max_workers=max_workers) as executor:
        futures = {executor.submit(_compress_single, t): t for t in tasks}
        for future in as_completed(futures):
            priority, base_name, qp_val, ok, err_msg = future.result()
            if ok:
                print(f"âœ… [{priority}] {base_name} ì••ì¶• ì™„ë£Œ (QP {qp_val})")
            else:
                print(f"âŒ [{priority}] {base_name} ì••ì¶• ì‹¤íŒ¨ (QP {qp_val}): {err_msg}")


def build_job_df(metadata_path=None, analysis_path=None):
    """metadata_vcm + vcm_analysis_reportë¥¼ ë³‘í•©í•˜ê³  compress_priority ìˆœ ì •ë ¬ (ê³µí†µ job_df.csv ì‚¬ìš©)"""
    os.makedirs(cfg.OUTPUT_REPORT_DIR, exist_ok=True)
    job_csv_path = os.path.join(cfg.OUTPUT_REPORT_DIR, "job_df.csv")

    if os.path.exists(job_csv_path):
        print(f"âœ… ê¸°ì¡´ job_df.csv ë°œê²¬: {job_csv_path}")
        return pd.read_csv(job_csv_path)

    if metadata_path is None:
        metadata_path = os.path.join(cfg.OUTPUT_METADATA_DIR, "metadata_vcm.csv")
    if analysis_path is None:
        analysis_path = os.path.join(cfg.OUTPUT_ANALYSIS_DIR, "vcm_analysis_report.csv")

    if not os.path.exists(metadata_path):
        raise FileNotFoundError(
            f"metadata_vcm.csv ì—†ìŒ. step1ì„ ë¨¼ì € ì‹¤í–‰: {metadata_path}"
        )
    if not os.path.exists(analysis_path):
        raise FileNotFoundError(
            f"vcm_analysis_report.csv ì—†ìŒ. step2ë¥¼ ë¨¼ì € ì‹¤í–‰: {analysis_path}"
        )

    meta_df = pd.read_csv(metadata_path)
    meta_df = meta_df[meta_df["is_valid"].isin([True, "True", "TRUE", 1])].copy()

    analysis_df = pd.read_csv(analysis_path)
    analysis_df = analysis_df[["file_name", "compress_priority"]].copy()

    job_df = meta_df.merge(analysis_df, on="file_name", how="inner")
    job_df = job_df.sort_values(by="compress_priority", ascending=True).reset_index(
        drop=True
    )

    job_df.to_csv(job_csv_path, index=False)
    print(f"âœ… job_df.csv ìƒì„±ë¨: {job_csv_path}")
    return job_df


def run_compress_vvc():
    input_root = cfg.ROI_PATH
    output_root = cfg.OUTPUT_COMPRESSED_VVC_DIR

    job_df = build_job_df()

    # VVC ì¸ì½”ë”©ì€ ë¦¬ì†ŒìŠ¤ë¥¼ ë§ì´ ì‚¬ìš©í•˜ë¯€ë¡œ ì›Œì»¤ ìˆ˜ë¥¼ ì ì ˆíˆ ì¡°ì ˆ
    n_workers = 4
    print(f"ğŸ“Š ì••ì¶• ëŒ€ìƒ {len(job_df)}ê°œ (compress_priority ìˆœ, {n_workers} ì›Œì»¤ ë³‘ë ¬)")

    qp_list = cfg.QP_LIST
    for qp in qp_list:
        qp_dir = os.path.join(output_root, f"qp{qp}")
        if not os.path.exists(qp_dir):
            os.makedirs(qp_dir, exist_ok=True)
        print(f"\nğŸš€ QP {qp} ì••ì¶• ì‹œì‘...")
        compress_vcm_vvc(input_root, output_root, qp, job_df, max_workers=n_workers)

    # ëª¨ë“  ì••ì¶•ì´ ëë‚œ í›„ ZIP íŒŒì¼ ìƒì„±
    zip_base_name = os.path.join(os.path.dirname(output_root), "compress_vvc")
    print(f"\nğŸ“¦ ì••ì¶• ê²°ê³¼ ZIP íŒŒì¼ ìƒì„± ì¤‘: {zip_base_name}.zip")
    shutil.make_archive(zip_base_name, "zip", output_root)
    print("âœ… ZIP íŒŒì¼ ìƒì„± ì™„ë£Œ")


if __name__ == "__main__":
    run_compress_vvc()
